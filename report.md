ğŸ“˜ **Backstoryâ€“Narrative Consistency Verification System**
Track A: Systems Reasoning with NLP & Generative AI
1. ğŸ§© Problem Statement

Input

A full-length novel (100k+ words)

A hypothetical backstory for a central character

Task
Determine whether the proposed backstory is consistent with the narrative as a whole.

This goes beyond surface-level contradiction detection.
The system verifies:

Consistency over time

Causal coherence

Respect for narrative constraints

Evidence-based reasoning across the text

2. ğŸ§  System Overview

We model the task as hypothesis verification:

Novel â†’ Ground truth

Backstory â†’ Hypothesis

The system combines semantic retrieval, claim-level reasoning, and deterministic aggregation to produce a final binary decision.

ğŸ”— High-Level Pipeline
Full Novel
 â†’ Chunking & Indexing (Pathway)
 â†’ Hypothetical Backstory
 â†’ Claim Decomposition
 â†’ Semantic Evidence Retrieval
 â†’ Claim-Level Reasoning (LLM)
 â†’ Deterministic Aggregation
 â†’ Final Binary Decision (results.csv)

 
3. ğŸ“š Long-Context Handling: Novel Chunking & Indexing

The complete novel is processed without truncation.

Chunking Strategy

The novel is split into overlapping text chunks

Each chunk represents a localized narrative unit (scene / paragraph group)

Every chunk is assigned a unique chunk_id

Benefits

Scalable handling of long narratives

Focused evidence retrieval

Preservation of global narrative coherence

4. ğŸ§± Pathway Integration (Track A Requirement)

Pathwayâ€™s Python framework serves as the semantic retrieval backbone.

Pathway is used to:

Ingest and store novel chunks

Generate semantic embeddings

Build a vector index for meaning-based search

Retrieve narrative evidence relevant to backstory claims

ğŸ” Semantic indexing enables retrieval by meaning rather than exact keywords, which is essential for reasoning about character behavior and development.

5. ğŸ§¬ Hypothetical Backstory & Claim Decomposition

The hypothetical backstory is provided as an external input (not generated by the system).

To enable structured evaluation, the backstory is decomposed into atomic, testable claims, such as:

Beliefs

Fears

Motivations

Formative experiences

Worldview assumptions

Each claim is labeled as:

Core â†’ Fundamental to character identity or long-term motivation

Non-core â†’ Secondary or contextual detail

This avoids vague, holistic judgments and enables precise reasoning.

6. ğŸ” Semantic Retrieval of Narrative Evidence

For each backstory claim:

A semantic query is issued to the Pathway index

Multiple relevant narrative chunks are retrieved

Evidence may include:

Actions

Dialogue

Internal monologue

Repeated behavioral patterns

This ensures decisions are grounded in signals from multiple parts of the text, not isolated passages.

7. ğŸ¤– Claim-Level Consistency Reasoning (LLM)

Each claim is evaluated against the retrieved evidence using an LLM.

The model assesses:

Whether the claim is supported, contradicted, or unconstrained

Whether it preserves causal consistency

Whether character behavior remains coherent over time

Output Encoding

score = 1 â†’ Consistent

score = 0 â†’ Contradictory

âš ï¸ Absence of evidence is not treated as contradiction.

8. ğŸ§® Deterministic Aggregation Logic

Claim-level results are combined using a frozen, deterministic rule:

If any core claim has score = 0 â†’ Contradict (0)

Otherwise â†’ Consistent (1)

This prevents critical contradictions from being diluted by majority voting or probabilistic averaging.

9. ğŸ“¥ Input & ğŸ“¤ Output Specification
Input (Placeholder Structure)
{
  "story_XXX": {
    "claims": [
      {
        "claim_id": "claim_1",
        "score": 0 or 1,
        "core": true or false
      }
    ]
  }
}

Output (results.csv)
story_id,prediction,rationale


Fields

story_id â†’ Unique identifier

prediction â†’ 1 (Consistent) / 0 (Contradict)

rationale â†’ Short human-readable explanation

Dummy Example

story_XXX,0,<a core backstory claim contradicts the narrative>
story_YYY,1,<all core backstory claims are consistent>

10. ğŸ Conclusion

This system provides a robust, explainable, and scalable approach to verifying backstoryâ€“narrative consistency in long-form fiction.

By combining:

Pathway-based semantic retrieval

Structured claim-level reasoning

Deterministic aggregation

the pipeline ensures evidence-grounded decisions while effectively handling long-context narratives.








